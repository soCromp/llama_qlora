{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonia/transformers-4.39.3/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from qlora import *\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "from os.path import exists, join, isdir\n",
    "from dataclasses import dataclass, field\n",
    "import sys\n",
    "from typing import Optional, Dict, Sequence\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from packaging import version\n",
    "from packaging.version import parse\n",
    "import warnings\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from torchmetrics.functional.pairwise import pairwise_manhattan_distance as manhattan\n",
    "from torchmetrics.functional.pairwise import pairwise_cosine_similarity as cossim\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import argparse\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    set_seed,\n",
    "    Seq2SeqTrainer,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaTokenizer\n",
    "\n",
    ")\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "import evaluate\n",
    "\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    PeftModel\n",
    ")\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "\n",
    "from transformers.modeling_utils import unwrap_model\n",
    "from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n",
    "from transformers.utils import is_peft_available\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "argdict = {\n",
    "  'model_name_or_path' : '/mnt/data/sonia/ckpts/clozehead/checkpoint-10', #'./mhllama',\n",
    "  'num_heads' : 5,\n",
    "  'max_column_len': 20,\n",
    "  'data_seed' : 42 ,\n",
    "  'do_eval': True,\n",
    "  'eval_dataset_size' : 5 ,\n",
    "  'max_eval_samples' : 2 ,\n",
    "  'per_device_eval_batch_size' : 1 ,\n",
    "  'max_new_tokens' : 60 ,\n",
    "  'dataloader_num_workers' : 1 ,\n",
    "  'group_by_length' : True,\n",
    "  'remove_unused_columns' : False ,\n",
    "  'lora_r' : 64 ,\n",
    "  'lora_alpha' : 16 ,\n",
    "  'lora_modules' : 'all' ,\n",
    "  'double_quant' : True,\n",
    "  'quant_type' : 'nf4' ,\n",
    "  'bf16' : True,\n",
    "  'bits' : 4 ,\n",
    "  'dataset' : '/mnt/data/sonia/honeygan/apr23.dat',\n",
    "  'source_max_len' : 60 ,\n",
    "  'target_max_len' : 60 ,\n",
    "  'seed' : 0\n",
    "}\n",
    "\n",
    "arglist = [f'--{k}={v}' for k,v in argdict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfparser = transformers.HfArgumentParser((\n",
    "    ModelArguments, DataArguments, TrainingArguments, GenerationArguments\n",
    "))\n",
    "model_args, data_args, training_args, generation_args  = hfparser.parse_args_into_dataclasses(args=arglist, return_remaining_strings=True)[:-1]\n",
    "training_args.generation_config = transformers.GenerationConfig(**vars(generation_args))\n",
    "args = argparse.Namespace(\n",
    "    **vars(model_args), **vars(data_args), **vars(training_args)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading base model /mnt/data/sonia/ckpts/clozehead/checkpoint-60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonia/transformers-4.39.3/src/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading adapter weights from /mnt/data/sonia/ckpts/clozehead/checkpoint-60 led to unexpected keys not found in the model:  ['model.layers.0.mlp.down_proj.lora_A.default.weight', 'model.layers.0.mlp.down_proj.lora_B.default.weight', 'model.layers.0.mlp.gate_proj.lora_A.default.weight', 'model.layers.0.mlp.gate_proj.lora_B.default.weight', 'model.layers.0.mlp.up_proj.lora_A.default.weight', 'model.layers.0.mlp.up_proj.lora_B.default.weight', 'model.layers.1.mlp.down_proj.lora_A.default.weight', 'model.layers.1.mlp.down_proj.lora_B.default.weight', 'model.layers.1.mlp.gate_proj.lora_A.default.weight', 'model.layers.1.mlp.gate_proj.lora_B.default.weight', 'model.layers.1.mlp.up_proj.lora_A.default.weight', 'model.layers.1.mlp.up_proj.lora_B.default.weight', 'model.layers.2.mlp.down_proj.lora_A.default.weight', 'model.layers.2.mlp.down_proj.lora_B.default.weight', 'model.layers.2.mlp.gate_proj.lora_A.default.weight', 'model.layers.2.mlp.gate_proj.lora_B.default.weight', 'model.layers.2.mlp.up_proj.lora_A.default.weight', 'model.layers.2.mlp.up_proj.lora_B.default.weight', 'model.layers.3.mlp.down_proj.lora_A.default.weight', 'model.layers.3.mlp.down_proj.lora_B.default.weight', 'model.layers.3.mlp.gate_proj.lora_A.default.weight', 'model.layers.3.mlp.gate_proj.lora_B.default.weight', 'model.layers.3.mlp.up_proj.lora_A.default.weight', 'model.layers.3.mlp.up_proj.lora_B.default.weight', 'model.layers.4.mlp.down_proj.lora_A.default.weight', 'model.layers.4.mlp.down_proj.lora_B.default.weight', 'model.layers.4.mlp.gate_proj.lora_A.default.weight', 'model.layers.4.mlp.gate_proj.lora_B.default.weight', 'model.layers.4.mlp.up_proj.lora_A.default.weight', 'model.layers.4.mlp.up_proj.lora_B.default.weight', 'model.layers.5.mlp.down_proj.lora_A.default.weight', 'model.layers.5.mlp.down_proj.lora_B.default.weight', 'model.layers.5.mlp.gate_proj.lora_A.default.weight', 'model.layers.5.mlp.gate_proj.lora_B.default.weight', 'model.layers.5.mlp.up_proj.lora_A.default.weight', 'model.layers.5.mlp.up_proj.lora_B.default.weight', 'model.layers.6.mlp.down_proj.lora_A.default.weight', 'model.layers.6.mlp.down_proj.lora_B.default.weight', 'model.layers.6.mlp.gate_proj.lora_A.default.weight', 'model.layers.6.mlp.gate_proj.lora_B.default.weight', 'model.layers.6.mlp.up_proj.lora_A.default.weight', 'model.layers.6.mlp.up_proj.lora_B.default.weight', 'model.layers.7.mlp.down_proj.lora_A.default.weight', 'model.layers.7.mlp.down_proj.lora_B.default.weight', 'model.layers.7.mlp.gate_proj.lora_A.default.weight', 'model.layers.7.mlp.gate_proj.lora_B.default.weight', 'model.layers.7.mlp.up_proj.lora_A.default.weight', 'model.layers.7.mlp.up_proj.lora_B.default.weight', 'model.layers.8.mlp.down_proj.lora_A.default.weight', 'model.layers.8.mlp.down_proj.lora_B.default.weight', 'model.layers.8.mlp.gate_proj.lora_A.default.weight', 'model.layers.8.mlp.gate_proj.lora_B.default.weight', 'model.layers.8.mlp.up_proj.lora_A.default.weight', 'model.layers.8.mlp.up_proj.lora_B.default.weight', 'model.layers.9.mlp.down_proj.lora_A.default.weight', 'model.layers.9.mlp.down_proj.lora_B.default.weight', 'model.layers.9.mlp.gate_proj.lora_A.default.weight', 'model.layers.9.mlp.gate_proj.lora_B.default.weight', 'model.layers.9.mlp.up_proj.lora_A.default.weight', 'model.layers.9.mlp.up_proj.lora_B.default.weight', 'model.layers.10.mlp.down_proj.lora_A.default.weight', 'model.layers.10.mlp.down_proj.lora_B.default.weight', 'model.layers.10.mlp.gate_proj.lora_A.default.weight', 'model.layers.10.mlp.gate_proj.lora_B.default.weight', 'model.layers.10.mlp.up_proj.lora_A.default.weight', 'model.layers.10.mlp.up_proj.lora_B.default.weight', 'model.layers.11.mlp.down_proj.lora_A.default.weight', 'model.layers.11.mlp.down_proj.lora_B.default.weight', 'model.layers.11.mlp.gate_proj.lora_A.default.weight', 'model.layers.11.mlp.gate_proj.lora_B.default.weight', 'model.layers.11.mlp.up_proj.lora_A.default.weight', 'model.layers.11.mlp.up_proj.lora_B.default.weight', 'model.layers.12.mlp.down_proj.lora_A.default.weight', 'model.layers.12.mlp.down_proj.lora_B.default.weight', 'model.layers.12.mlp.gate_proj.lora_A.default.weight', 'model.layers.12.mlp.gate_proj.lora_B.default.weight', 'model.layers.12.mlp.up_proj.lora_A.default.weight', 'model.layers.12.mlp.up_proj.lora_B.default.weight', 'model.layers.13.mlp.down_proj.lora_A.default.weight', 'model.layers.13.mlp.down_proj.lora_B.default.weight', 'model.layers.13.mlp.gate_proj.lora_A.default.weight', 'model.layers.13.mlp.gate_proj.lora_B.default.weight', 'model.layers.13.mlp.up_proj.lora_A.default.weight', 'model.layers.13.mlp.up_proj.lora_B.default.weight', 'model.layers.14.mlp.down_proj.lora_A.default.weight', 'model.layers.14.mlp.down_proj.lora_B.default.weight', 'model.layers.14.mlp.gate_proj.lora_A.default.weight', 'model.layers.14.mlp.gate_proj.lora_B.default.weight', 'model.layers.14.mlp.up_proj.lora_A.default.weight', 'model.layers.14.mlp.up_proj.lora_B.default.weight', 'model.layers.15.mlp.down_proj.lora_A.default.weight', 'model.layers.15.mlp.down_proj.lora_B.default.weight', 'model.layers.15.mlp.gate_proj.lora_A.default.weight', 'model.layers.15.mlp.gate_proj.lora_B.default.weight', 'model.layers.15.mlp.up_proj.lora_A.default.weight', 'model.layers.15.mlp.up_proj.lora_B.default.weight', 'model.layers.16.mlp.down_proj.lora_A.default.weight', 'model.layers.16.mlp.down_proj.lora_B.default.weight', 'model.layers.16.mlp.gate_proj.lora_A.default.weight', 'model.layers.16.mlp.gate_proj.lora_B.default.weight', 'model.layers.16.mlp.up_proj.lora_A.default.weight', 'model.layers.16.mlp.up_proj.lora_B.default.weight', 'model.layers.17.mlp.down_proj.lora_A.default.weight', 'model.layers.17.mlp.down_proj.lora_B.default.weight', 'model.layers.17.mlp.gate_proj.lora_A.default.weight', 'model.layers.17.mlp.gate_proj.lora_B.default.weight', 'model.layers.17.mlp.up_proj.lora_A.default.weight', 'model.layers.17.mlp.up_proj.lora_B.default.weight', 'model.layers.18.mlp.down_proj.lora_A.default.weight', 'model.layers.18.mlp.down_proj.lora_B.default.weight', 'model.layers.18.mlp.gate_proj.lora_A.default.weight', 'model.layers.18.mlp.gate_proj.lora_B.default.weight', 'model.layers.18.mlp.up_proj.lora_A.default.weight', 'model.layers.18.mlp.up_proj.lora_B.default.weight', 'model.layers.19.mlp.down_proj.lora_A.default.weight', 'model.layers.19.mlp.down_proj.lora_B.default.weight', 'model.layers.19.mlp.gate_proj.lora_A.default.weight', 'model.layers.19.mlp.gate_proj.lora_B.default.weight', 'model.layers.19.mlp.up_proj.lora_A.default.weight', 'model.layers.19.mlp.up_proj.lora_B.default.weight', 'model.layers.20.mlp.down_proj.lora_A.default.weight', 'model.layers.20.mlp.down_proj.lora_B.default.weight', 'model.layers.20.mlp.gate_proj.lora_A.default.weight', 'model.layers.20.mlp.gate_proj.lora_B.default.weight', 'model.layers.20.mlp.up_proj.lora_A.default.weight', 'model.layers.20.mlp.up_proj.lora_B.default.weight', 'model.layers.21.mlp.down_proj.lora_A.default.weight', 'model.layers.21.mlp.down_proj.lora_B.default.weight', 'model.layers.21.mlp.gate_proj.lora_A.default.weight', 'model.layers.21.mlp.gate_proj.lora_B.default.weight', 'model.layers.21.mlp.up_proj.lora_A.default.weight', 'model.layers.21.mlp.up_proj.lora_B.default.weight', 'model.layers.22.mlp.down_proj.lora_A.default.weight', 'model.layers.22.mlp.down_proj.lora_B.default.weight', 'model.layers.22.mlp.gate_proj.lora_A.default.weight', 'model.layers.22.mlp.gate_proj.lora_B.default.weight', 'model.layers.22.mlp.up_proj.lora_A.default.weight', 'model.layers.22.mlp.up_proj.lora_B.default.weight', 'model.layers.23.mlp.down_proj.lora_A.default.weight', 'model.layers.23.mlp.down_proj.lora_B.default.weight', 'model.layers.23.mlp.gate_proj.lora_A.default.weight', 'model.layers.23.mlp.gate_proj.lora_B.default.weight', 'model.layers.23.mlp.up_proj.lora_A.default.weight', 'model.layers.23.mlp.up_proj.lora_B.default.weight', 'model.layers.24.mlp.down_proj.lora_A.default.weight', 'model.layers.24.mlp.down_proj.lora_B.default.weight', 'model.layers.24.mlp.gate_proj.lora_A.default.weight', 'model.layers.24.mlp.gate_proj.lora_B.default.weight', 'model.layers.24.mlp.up_proj.lora_A.default.weight', 'model.layers.24.mlp.up_proj.lora_B.default.weight', 'model.layers.25.mlp.down_proj.lora_A.default.weight', 'model.layers.25.mlp.down_proj.lora_B.default.weight', 'model.layers.25.mlp.gate_proj.lora_A.default.weight', 'model.layers.25.mlp.gate_proj.lora_B.default.weight', 'model.layers.25.mlp.up_proj.lora_A.default.weight', 'model.layers.25.mlp.up_proj.lora_B.default.weight', 'model.layers.26.mlp.down_proj.lora_A.default.weight', 'model.layers.26.mlp.down_proj.lora_B.default.weight', 'model.layers.26.mlp.gate_proj.lora_A.default.weight', 'model.layers.26.mlp.gate_proj.lora_B.default.weight', 'model.layers.26.mlp.up_proj.lora_A.default.weight', 'model.layers.26.mlp.up_proj.lora_B.default.weight', 'model.layers.27.mlp.down_proj.lora_A.default.weight', 'model.layers.27.mlp.down_proj.lora_B.default.weight', 'model.layers.27.mlp.gate_proj.lora_A.default.weight', 'model.layers.27.mlp.gate_proj.lora_B.default.weight', 'model.layers.27.mlp.up_proj.lora_A.default.weight', 'model.layers.27.mlp.up_proj.lora_B.default.weight', 'model.layers.28.mlp.down_proj.lora_A.default.weight', 'model.layers.28.mlp.down_proj.lora_B.default.weight', 'model.layers.28.mlp.gate_proj.lora_A.default.weight', 'model.layers.28.mlp.gate_proj.lora_B.default.weight', 'model.layers.28.mlp.up_proj.lora_A.default.weight', 'model.layers.28.mlp.up_proj.lora_B.default.weight', 'model.layers.29.mlp.down_proj.lora_A.default.weight', 'model.layers.29.mlp.down_proj.lora_B.default.weight', 'model.layers.29.mlp.gate_proj.lora_A.default.weight', 'model.layers.29.mlp.gate_proj.lora_B.default.weight', 'model.layers.29.mlp.up_proj.lora_A.default.weight', 'model.layers.29.mlp.up_proj.lora_B.default.weight', 'model.layers.30.mlp.down_proj.lora_A.default.weight', 'model.layers.30.mlp.down_proj.lora_B.default.weight', 'model.layers.30.mlp.gate_proj.lora_A.default.weight', 'model.layers.30.mlp.gate_proj.lora_B.default.weight', 'model.layers.30.mlp.up_proj.lora_A.default.weight', 'model.layers.30.mlp.up_proj.lora_B.default.weight', 'model.layers.31.mlp.down_proj.lora_A.default.weight', 'model.layers.31.mlp.down_proj.lora_B.default.weight', 'model.layers.31.mlp.gate_proj.lora_A.default.weight', 'model.layers.31.mlp.gate_proj.lora_B.default.weight', 'model.layers.31.mlp.up_proj.lora_A.default.weight', 'model.layers.31.mlp.up_proj.lora_B.default.weight']. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MH llama has 5 heads\n",
      "Adding special tokens.\n",
      "adding LoRA modules...\n",
      "['base_layer']\n",
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir, completed_training = get_last_checkpoint(args.output_dir)\n",
    "model, tokenizer = get_accelerate_model(args, checkpoint_dir)\n",
    "model.config.use_cache = False\n",
    "    \n",
    "print('loaded model')\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "collator = data_module['data_collator']\n",
    "datatr = data_module['train_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainerclass = Seq2SeqTrainer\n",
    "trainer = trainerclass(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    **{k:v for k,v in data_module.items() if k != 'predict_dataset'},\n",
    ")\n",
    "class evalSampleCallback(transformers.TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, model, **kwargs):\n",
    "        trainer.model.eval()\n",
    "        metrics = trainer.predict(test_dataset=data_module['eval_dataset'],metric_key_prefix=\"predict\")\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(len(metrics.predictions)):\n",
    "            logit = metrics.predictions[i]\n",
    "            label = metrics.label_ids[i] #just to see positions where prompt tokens are at\n",
    "            logit_abcd = logit[label != IGNORE_INDEX]\n",
    "            toks = np.argmax(logit_abcd, axis=1)\n",
    "            predictions.append(\n",
    "                ''.join(trainer.tokenizer.decode(toks, skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "                )\n",
    "        \n",
    "        for pred in predictions:\n",
    "            print(pred)\n",
    "    \n",
    "    \n",
    "trainer.add_callback(evalSampleCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.set_trace(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29874, 29900, 29906, 29901, 29896, 29947, 29896,\n",
      "         29896, 29901, 29929, 29883, 29947, 29896, 29901,   600, 29900, 29900,\n",
      "         29901, 29906, 29896, 29896, 29901, 29941, 29906,   600, 29901,  1725,\n",
      "         29953, 29946, 29901, 29953, 29945,  1725,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29874, 29900, 29906, 29901, 29896, 29947, 29896,\n",
      "         29896, 29901, 29929, 29883, 29947, 29896, 29901,   600, 29900, 29900,\n",
      "         29901, 29906, 29896, 29896, 29901, 29941, 29906,   600, 29901,  1725,\n",
      "         29953, 29946, 29901, 29953, 29945,  1725,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29874, 29900, 29906, 29901, 29896, 29947, 29896,\n",
      "         29896, 29901, 29929, 29883, 29947, 29896, 29901,   600, 29900, 29900,\n",
      "         29901, 29906, 29896, 29896, 29901, 29941, 29906,   600, 29901,  1725,\n",
      "         29953, 29946, 29901, 29953, 29945,  1725,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29874, 29900, 29906, 29901, 29896, 29947, 29896,\n",
      "         29896, 29901, 29929, 29883, 29947, 29896, 29901,   600, 29900, 29900,\n",
      "         29901, 29906, 29896, 29896, 29901, 29941, 29906,   600, 29901,  1725,\n",
      "         29953, 29946, 29901, 29953, 29945,  1725,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29955, 29945, 29889,\n",
      "         29906, 29906, 29955, 29889, 29906, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29896,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  2045, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29955, 29945, 29889,\n",
      "         29906, 29906, 29955, 29889, 29906, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29896,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  2045, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29955, 29945, 29889,\n",
      "         29906, 29906, 29955, 29889, 29906, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29896,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  2045, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29955, 29945, 29889,\n",
      "         29906, 29906, 29955, 29889, 29906, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29896,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  2045, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29945, 29941, 29889, 29896, 29947, 29929,\n",
      "         29889, 29896, 29953, 29947, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29945, 29941, 29889, 29896, 29947, 29929,\n",
      "         29889, 29896, 29953, 29947, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29945, 29941, 29889, 29896, 29947, 29929,\n",
      "         29889, 29896, 29953, 29947, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29945, 29941, 29889, 29896, 29947, 29929,\n",
      "         29889, 29896, 29953, 29947, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29896, 29889, 29896, 29945, 29896,\n",
      "         29889, 29896, 29906, 29900, 29889, 29896, 29945, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29896, 29889, 29896, 29945, 29896,\n",
      "         29889, 29896, 29906, 29900, 29889, 29896, 29945, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29896, 29889, 29896, 29945, 29896,\n",
      "         29889, 29896, 29906, 29900, 29889, 29896, 29945, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29896, 29889, 29896, 29945, 29896,\n",
      "         29889, 29896, 29906, 29900, 29889, 29896, 29945, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29896, 29955, 29889, 29906, 29945, 29946,\n",
      "         29889, 29896, 29900, 29941, 29889, 29906, 29945, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29896, 29955, 29889, 29906, 29945, 29946,\n",
      "         29889, 29896, 29900, 29941, 29889, 29906, 29945, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29896, 29955, 29889, 29906, 29945, 29946,\n",
      "         29889, 29896, 29900, 29941, 29889, 29906, 29945, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29896, 29955, 29889, 29906, 29945, 29946,\n",
      "         29889, 29896, 29900, 29941, 29889, 29906, 29945, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29906, 29941, 29929,\n",
      "         29889, 29896, 29953, 29896, 29889, 29896, 29947, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29906, 29941, 29929,\n",
      "         29889, 29896, 29953, 29896, 29889, 29896, 29947, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29906, 29941, 29929,\n",
      "         29889, 29896, 29953, 29896, 29889, 29896, 29947, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29906, 29941, 29929,\n",
      "         29889, 29896, 29953, 29896, 29889, 29896, 29947, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29896, 29941, 29941,\n",
      "         29889, 29896, 29946, 29929, 29889, 29906, 29946, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29896, 29941, 29941,\n",
      "         29889, 29896, 29946, 29929, 29889, 29906, 29946, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29896, 29941, 29941,\n",
      "         29889, 29896, 29946, 29929, 29889, 29906, 29946, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29945, 29889, 29896, 29941, 29941,\n",
      "         29889, 29896, 29946, 29929, 29889, 29906, 29946, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29896, 29929, 29945,\n",
      "         29889, 29896, 29947, 29955, 29889, 29906, 29941, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29896, 29929, 29945,\n",
      "         29889, 29896, 29947, 29955, 29889, 29906, 29941, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29896, 29929, 29945,\n",
      "         29889, 29896, 29947, 29955, 29889, 29906, 29941, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29896, 29929, 29945,\n",
      "         29889, 29896, 29947, 29955, 29889, 29906, 29941, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29906, 29889, 29906, 29896, 29896,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29906, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29906, 29889, 29906, 29896, 29896,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29906, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29906, 29889, 29906, 29896, 29896,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29906, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29906, 29889, 29906, 29896, 29896,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29906, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29900, 29889, 29896, 29941, 29906,\n",
      "         29889, 29896, 29947, 29929, 29889, 29896, 29955, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29900, 29889, 29896, 29941, 29906,\n",
      "         29889, 29896, 29947, 29929, 29889, 29896, 29955, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29900, 29889, 29896, 29941, 29906,\n",
      "         29889, 29896, 29947, 29929, 29889, 29896, 29955, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29906, 29906, 29900, 29889, 29896, 29941, 29906,\n",
      "         29889, 29896, 29947, 29929, 29889, 29896, 29955, 29900,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29906, 29889, 29896, 29945, 29900,\n",
      "         29889, 29896, 29947, 29955, 29889, 29896, 29955, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29906, 29889, 29896, 29945, 29900,\n",
      "         29889, 29896, 29947, 29955, 29889, 29896, 29955, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29906, 29889, 29896, 29945, 29900,\n",
      "         29889, 29896, 29947, 29955, 29889, 29896, 29955, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29906, 29889, 29896, 29945, 29900,\n",
      "         29889, 29896, 29947, 29955, 29889, 29896, 29955, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29947, 29889, 29896, 29900, 29953,\n",
      "         29889, 29896, 29929, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29947, 29889, 29896, 29900, 29953,\n",
      "         29889, 29896, 29929, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29947, 29889, 29896, 29900, 29953,\n",
      "         29889, 29896, 29929, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29947, 29889, 29896, 29900, 29953,\n",
      "         29889, 29896, 29929, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29946, 29889, 29906, 29946, 29945,\n",
      "         29889, 29896, 29929, 29929, 29889, 29896, 29953, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29946, 29889, 29906, 29946, 29945,\n",
      "         29889, 29896, 29929, 29929, 29889, 29896, 29953, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29946, 29889, 29906, 29946, 29945,\n",
      "         29889, 29896, 29929, 29929, 29889, 29896, 29953, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29896, 29946, 29889, 29906, 29946, 29945,\n",
      "         29889, 29896, 29929, 29929, 29889, 29896, 29953, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29945, 29889, 29896, 29929, 29906,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29929, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29945, 29889, 29896, 29929, 29906,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29929, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29945, 29889, 29896, 29929, 29906,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29929, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29945, 29889, 29896, 29929, 29906,\n",
      "         29889, 29896, 29955, 29955, 29889, 29896, 29929, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29906, 29889, 29896, 29941, 29953,\n",
      "         29889, 29896, 29955, 29900, 29889, 29906, 29900, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29906, 29889, 29896, 29941, 29953,\n",
      "         29889, 29896, 29955, 29900, 29889, 29906, 29900, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29906, 29889, 29896, 29941, 29953,\n",
      "         29889, 29896, 29955, 29900, 29889, 29906, 29900, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29906, 29889, 29896, 29941, 29953,\n",
      "         29889, 29896, 29955, 29900, 29889, 29906, 29900, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29941, 29889, 29896, 29945, 29929,\n",
      "         29889, 29896, 29955, 29929, 29889, 29906, 29900, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29941, 29889, 29896, 29945, 29929,\n",
      "         29889, 29896, 29955, 29929, 29889, 29906, 29900, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29941, 29889, 29896, 29945, 29929,\n",
      "         29889, 29896, 29955, 29929, 29889, 29906, 29900, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29906, 29941, 29889, 29896, 29945, 29929,\n",
      "         29889, 29896, 29955, 29929, 29889, 29906, 29900, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/10000 01:30 < 252:14:05, 0.01 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29953, 29889, 29896, 29896, 29947,\n",
      "         29889, 29896, 29955, 29941, 29889, 29906, 29941, 29945,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29953, 29889, 29896, 29896, 29947,\n",
      "         29889, 29896, 29955, 29941, 29889, 29906, 29941, 29945,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29953, 29889, 29896, 29896, 29947,\n",
      "         29889, 29896, 29955, 29941, 29889, 29906, 29941, 29945,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29955, 29953, 29889, 29896, 29896, 29947,\n",
      "         29889, 29896, 29955, 29941, 29889, 29906, 29941, 29945,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29906, 29946, 29945,\n",
      "         29889, 29906, 29906, 29900, 29889, 29896, 29900, 29929,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29906, 29946, 29945,\n",
      "         29889, 29906, 29906, 29900, 29889, 29896, 29900, 29929,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29906, 29946, 29945,\n",
      "         29889, 29906, 29906, 29900, 29889, 29896, 29900, 29929,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29900, 29929, 29889, 29906, 29946, 29945,\n",
      "         29889, 29906, 29906, 29900, 29889, 29896, 29900, 29929,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29947, 29889, 29896, 29929, 29946,\n",
      "         29889, 29896, 29953, 29929, 29889, 29906, 29906, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29947, 29889, 29896, 29929, 29946,\n",
      "         29889, 29896, 29953, 29929, 29889, 29906, 29906, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29947, 29889, 29896, 29929, 29946,\n",
      "         29889, 29896, 29953, 29929, 29889, 29906, 29906, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29947, 29889, 29896, 29929, 29946,\n",
      "         29889, 29896, 29953, 29929, 29889, 29906, 29906, 29947,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29929, 29906, 29889, 29896, 29953, 29946,\n",
      "         29889, 29906, 29896, 29955, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29929, 29906, 29889, 29896, 29953, 29946,\n",
      "         29889, 29906, 29896, 29955, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29929, 29906, 29889, 29896, 29953, 29946,\n",
      "         29889, 29906, 29896, 29955, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29929, 29906, 29889, 29896, 29953, 29946,\n",
      "         29889, 29906, 29896, 29955, 29889, 29906, 29896, 29946,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29955, 29929,\n",
      "         29889, 29896, 29945, 29946, 29889, 29906, 29896, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29955, 29929,\n",
      "         29889, 29896, 29945, 29946, 29889, 29906, 29896, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29955, 29929,\n",
      "         29889, 29896, 29945, 29946, 29889, 29906, 29896, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29955, 29929,\n",
      "         29889, 29896, 29945, 29946, 29889, 29906, 29896, 29941,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29900, 29929,\n",
      "         29889, 29896, 29896, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29900, 29929,\n",
      "         29889, 29896, 29896, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29900, 29929,\n",
      "         29889, 29896, 29896, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True]], device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3,     2, 29871, 29896, 29947, 29941, 29889, 29896, 29900, 29929,\n",
      "         29889, 29896, 29896, 29946, 29889, 29896, 29946, 29906,     0,     3,\n",
      "         29892,  2011, 29871, 29871, 29945, 29900, 29900, 29900,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             3, 29892, 27032,  2669, 29871,  1732, 29899, 12857, 29899,  1482,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     3]], device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29953, 29889, 29896, 29946, 29896, 29889,\n",
      "         29896, 29900, 29929, 29889, 29947, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29953, 29889, 29896, 29946, 29896, 29889,\n",
      "         29896, 29900, 29929, 29889, 29947, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29953, 29889, 29896, 29946, 29896, 29889,\n",
      "         29896, 29900, 29929, 29889, 29947, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29953, 29889, 29896, 29946, 29896, 29889,\n",
      "         29896, 29900, 29929, 29889, 29947, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29941, 29947, 29889, 29906,\n",
      "         29945, 29896, 29889, 29896, 29947, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29941, 29947, 29889, 29906,\n",
      "         29945, 29896, 29889, 29896, 29947, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29941, 29947, 29889, 29906,\n",
      "         29945, 29896, 29889, 29896, 29947, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29941, 29947, 29889, 29906,\n",
      "         29945, 29896, 29889, 29896, 29947, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29945, 29889, 29896, 29941, 29945, 29889, 29896,\n",
      "         29896, 29941, 29889, 29896, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29945, 29889, 29896, 29941, 29945, 29889, 29896,\n",
      "         29896, 29941, 29889, 29896, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29945, 29889, 29896, 29941, 29945, 29889, 29896,\n",
      "         29896, 29941, 29889, 29896, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29945, 29889, 29896, 29941, 29945, 29889, 29896,\n",
      "         29896, 29941, 29889, 29896, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29896, 29906, 29953, 29889, 29896,\n",
      "         29946, 29896, 29889, 29906, 29941, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29896, 29906, 29953, 29889, 29896,\n",
      "         29946, 29896, 29889, 29906, 29941, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29896, 29906, 29953, 29889, 29896,\n",
      "         29946, 29896, 29889, 29906, 29941, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29896, 29906, 29953, 29889, 29896,\n",
      "         29946, 29896, 29889, 29906, 29941, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29946, 29929, 29889, 29941, 29953, 29889, 29896,\n",
      "         29929, 29945, 29889, 29896, 29945, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29946, 29929, 29889, 29941, 29953, 29889, 29896,\n",
      "         29929, 29945, 29889, 29896, 29945, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29946, 29929, 29889, 29941, 29953, 29889, 29896,\n",
      "         29929, 29945, 29889, 29896, 29945, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29946, 29929, 29889, 29941, 29953, 29889, 29896,\n",
      "         29929, 29945, 29889, 29896, 29945, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29946, 29941, 29889,\n",
      "         29896, 29953, 29945, 29889, 29953, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29946, 29941, 29889,\n",
      "         29896, 29953, 29945, 29889, 29953, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29946, 29941, 29889,\n",
      "         29896, 29953, 29945, 29889, 29953, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29946, 29941, 29889,\n",
      "         29896, 29953, 29945, 29889, 29953, 29945,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29945, 29889, 29896, 29946, 29946, 29889,\n",
      "         29906, 29941, 29896, 29889, 29941, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29945, 29889, 29896, 29946, 29946, 29889,\n",
      "         29906, 29941, 29896, 29889, 29941, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29945, 29889, 29896, 29946, 29946, 29889,\n",
      "         29906, 29941, 29896, 29889, 29941, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29955, 29945, 29889, 29896, 29946, 29946, 29889,\n",
      "         29906, 29941, 29896, 29889, 29941, 29900,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29906, 29906, 29889, 29896,\n",
      "         29941, 29947, 29889, 29906, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29906, 29906, 29889, 29896,\n",
      "         29941, 29947, 29889, 29906, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29906, 29906, 29889, 29896,\n",
      "         29941, 29947, 29889, 29906, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29947, 29955, 29889, 29896, 29906, 29906, 29889, 29896,\n",
      "         29941, 29947, 29889, 29906, 29900, 29953,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29947, 29900, 29947, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29896, 29906, 29889, 29953, 29946, 29889, 29896,\n",
      "         29896, 29900, 29889, 29906, 29900, 29947,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29896, 29906, 29889, 29953, 29946, 29889, 29896,\n",
      "         29896, 29900, 29889, 29906, 29900, 29947,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29896, 29906, 29889, 29953, 29946, 29889, 29896,\n",
      "         29896, 29900, 29889, 29906, 29900, 29947,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29896, 29906, 29889, 29953, 29946, 29889, 29896,\n",
      "         29896, 29900, 29889, 29906, 29900, 29947,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29941, 29906, 29889,\n",
      "         29896, 29953, 29889, 29896, 29906, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29941, 29906, 29889,\n",
      "         29896, 29953, 29889, 29896, 29906, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29941, 29906, 29889,\n",
      "         29896, 29953, 29889, 29896, 29906, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29941, 29889, 29896, 29941, 29906, 29889,\n",
      "         29896, 29953, 29889, 29896, 29906, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29941, 29906, 29889, 29896, 29946, 29955, 29889,\n",
      "         29929, 29900, 29889, 29896, 29947, 29955,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29941, 29906, 29889, 29896, 29946, 29955, 29889,\n",
      "         29929, 29900, 29889, 29896, 29947, 29955,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29941, 29906, 29889, 29896, 29946, 29955, 29889,\n",
      "         29929, 29900, 29889, 29896, 29947, 29955,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29941, 29906, 29889, 29896, 29946, 29955, 29889,\n",
      "         29929, 29900, 29889, 29896, 29947, 29955,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29906, 29896, 29889, 29896, 29906, 29946, 29889,\n",
      "         29929, 29929, 29889, 29896, 29906, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29906, 29896, 29889, 29896, 29906, 29946, 29889,\n",
      "         29929, 29929, 29889, 29896, 29906, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29906, 29896, 29889, 29896, 29906, 29946, 29889,\n",
      "         29929, 29929, 29889, 29896, 29906, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29906, 29896, 29889, 29896, 29906, 29946, 29889,\n",
      "         29929, 29929, 29889, 29896, 29906, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29896, 29900, 29889, 29896, 29955, 29947, 29889,\n",
      "         29906, 29941, 29929, 29889, 29946, 29929,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29896, 29900, 29889, 29896, 29955, 29947, 29889,\n",
      "         29906, 29941, 29929, 29889, 29946, 29929,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29896, 29900, 29889, 29896, 29955, 29947, 29889,\n",
      "         29906, 29941, 29929, 29889, 29946, 29929,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29906, 29896, 29900, 29889, 29896, 29955, 29947, 29889,\n",
      "         29906, 29941, 29929, 29889, 29946, 29929,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29896, 29946, 29889,\n",
      "         29896, 29900, 29900, 29889, 29947, 29906,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29896, 29946, 29889,\n",
      "         29896, 29900, 29900, 29889, 29947, 29906,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29896, 29946, 29889,\n",
      "         29896, 29900, 29900, 29889, 29947, 29906,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29896, 29947, 29900, 29889, 29896, 29896, 29946, 29889,\n",
      "         29896, 29900, 29900, 29889, 29947, 29906,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29953, 29900, 29889, 29906, 29896, 29896, 29889, 29896,\n",
      "         29896, 29896, 29889, 29906, 29900, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29953, 29900, 29889, 29906, 29896, 29896, 29889, 29896,\n",
      "         29896, 29896, 29889, 29906, 29900, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29953, 29900, 29889, 29906, 29896, 29896, 29889, 29896,\n",
      "         29896, 29896, 29889, 29906, 29900, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29953, 29900, 29889, 29906, 29896, 29896, 29889, 29896,\n",
      "         29896, 29896, 29889, 29906, 29900, 29896,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "trainer compute_loss self.args.past_index -1\n",
      "in forward\n",
      "tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29906, 29941, 29945, 29889, 29896,\n",
      "         29941, 29953, 29889, 29896, 29946, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29906, 29941, 29945, 29889, 29896,\n",
      "         29941, 29953, 29889, 29896, 29946, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n",
      "in forward. input_ids tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29906, 29941, 29945, 29889, 29896,\n",
      "         29941, 29953, 29889, 29896, 29946, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0') attention mask tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True]],\n",
      "       device='cuda:0') label tensor([[    1, 29874, 29871,  5222,  3002,  8086, 19569,  8455,   313, 29881,\n",
      "          3844, 29897,     0,     0,     0,     0,     0,     0,     0,     3,\n",
      "             2, 29871, 29955, 29947, 29889, 29906, 29941, 29945, 29889, 29896,\n",
      "         29941, 29953, 29889, 29896, 29946, 29946,     0,     3, 29892,  2011,\n",
      "         29871, 29871, 29945, 29900, 29900, 29900,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     3, 29892, 27032,\n",
      "          2669, 29871,  1732, 29899, 12857, 29899,  1482,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     3]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/transformers-4.39.3/src/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1781\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1782\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1783\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1784\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1785\u001b[0m     )\n",
      "File \u001b[0;32m~/transformers-4.39.3/src/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/transformers-4.39.3/src/transformers/trainer.py:3036\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3036\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3039\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/transformers-4.39.3/src/transformers/trainer.py:3059\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3059\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   3060\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainer compute_loss self.args.past_index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/utils/operations.py:825\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/utils/operations.py:813\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/utils/operations.py:825\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/utils/operations.py:813\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: ConvertOutputsToFp32.__call__ at line 813 (3 times), autocast_decorator.<locals>.decorate_autocast at line 14 (3 times), convert_outputs_to_fp32.<locals>.forward at line 825 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/utils/operations.py:825\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/utils/operations.py:813\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/peft/peft_model.py:1073\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward in MPTForCausalLM does not support inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1063\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\n\u001b[1;32m   1064\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1065\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1071\u001b[0m         )\n\u001b[0;32m-> 1073\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\n\u001b[1;32m   1074\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1075\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1076\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1077\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1078\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1079\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1080\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1081\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1082\u001b[0m     )\n\u001b[1;32m   1084\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:103\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/llama-qlora/multihead_models.py:483\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, head_inds, input_ids, col, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    481\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[0;32m--> 483\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    484\u001b[0m     inputs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    485\u001b[0m     insert_indices: torch\u001b[38;5;241m.\u001b[39mLongTensor,\n\u001b[1;32m    486\u001b[0m     max_tokens_per_col: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    487\u001b[0m     generation_config: Optional[GenerationConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    488\u001b[0m     logits_processor: Optional[LogitsProcessorList] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    489\u001b[0m     stopping_criteria: Optional[StoppingCriteriaList] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    490\u001b[0m     prefix_allowed_tokens_fn: Optional[Callable[[\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], List[\u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    491\u001b[0m     synced_gpus: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m     assistant_model: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m     streamer: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseStreamer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m     negative_prompt_ids: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m     negative_prompt_attention_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    497\u001b[0m ):\n\u001b[1;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m    Copied from GenerationMixin (super) generate()\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    Generates sequences of token ids for models with a language modeling head.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m                - [`~generation.BeamSampleEncoderDecoderOutput`]\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min generate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/llama-qlora/multihead_models.py:205\u001b[0m, in \u001b[0;36mMOELlamaModel.forward\u001b[0;34m(self, column, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    202\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 205\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    206\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    207\u001b[0m         hidden_states,\n\u001b[1;32m    208\u001b[0m         column,\n\u001b[1;32m    209\u001b[0m         causal_mask,\n\u001b[1;32m    210\u001b[0m         position_ids,\n\u001b[1;32m    211\u001b[0m         past_key_values,\n\u001b[1;32m    212\u001b[0m         output_attentions,\n\u001b[1;32m    213\u001b[0m         use_cache,\n\u001b[1;32m    214\u001b[0m         cache_position,\n\u001b[1;32m    215\u001b[0m     )\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m    218\u001b[0m         hidden_states,\n\u001b[1;32m    219\u001b[0m         column,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/utils/checkpoint.py:249\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected keyword arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m kwargs))\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_reentrant:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointFunction\u001b[38;5;241m.\u001b[39mapply(function, preserve, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _checkpoint_without_reentrant(\n\u001b[1;32m    252\u001b[0m         function,\n\u001b[1;32m    253\u001b[0m         preserve,\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/utils/checkpoint.py:107\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 107\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m run_function(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/llama-qlora/multihead_models.py:94\u001b[0m, in \u001b[0;36mMOELlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, column, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m     95\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m     96\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m     97\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m     98\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m     99\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    100\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    101\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/transformers-4.39.3/src/transformers/models/llama/modeling_llama.py:397\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([F\u001b[38;5;241m.\u001b[39mlinear(attn_output[i], o_proj_slices[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp)])\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj(attn_output)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[1;32m    400\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:309\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     expected_dtype \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    307\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(lora_A\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 309\u001b[0m output \u001b[38;5;241m=\u001b[39m lora_B(lora_A(dropout(x)))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requires_conversion:\n\u001b[1;32m    311\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto(expected_dtype)\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.AutoConfig.register('mhllama', MHLlamaConfig)\n",
    "transformers.AutoModelForCausalLM.register(MHLlamaConfig, MultiheadLlamaForCausalLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonia/transformers-4.39.3/src/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/mnt/data/sonia/miniconda3/envs/llama/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "config = MHLlamaConfig(**vars(args))\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            config = config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiheadLlamaForCausalLM(\n",
       "  (model): MOELlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MOELlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): ModuleList(\n",
       "          (0-4): 5 x LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (heads): ModuleList(\n",
       "    (0-4): 5 x Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, join(args.model_name_or_path, 'adapter_model'), is_trainable=True)\n",
    "model = model.merge_and_unload()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/mnt/data/zoo/llama2/llama2-7b-hf/',\n",
    "        padding_side=\"right\",\n",
    "        use_fast=False, # Fast tokenizer giving issues.\n",
    "        )\n",
    "data_module = make_data_module(tokenizer=tokenizer, args=args)\n",
    "collator = data_module['data_collator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1]]),\n",
       " 'attention_mask': tensor([[1]]),\n",
       " 'head_inds': tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
       "         0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0,\n",
       "         0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = collator([{'length': 87}])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepared_logits_processor []\n",
      "prepared_stopping_criteria [<transformers.generation.stopping_criteria.MaxLengthCriteria object at 0x7fa0a9c83f90>]\n"
     ]
    }
   ],
   "source": [
    "model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a1843f88f7426eaddf47433502dcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonia/transformers-4.39.3/src/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/sonia/transformers-4.39.3/src/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/sonia/transformers-4.39.3/src/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/sonia/transformers-4.39.3/src/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\"/mnt/data/zoo/llama2/llama2-7b-hf/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/data/zoo/llama2/llama2-7b-hf/\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.lm_head.state_dict(), 'just_a_head.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in generate None None None\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 13])\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 14])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 13 cache_length 13 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 14])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13]])\n",
      "position_ids tensor([[13]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 15])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 14 cache_length 14 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 15])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]])\n",
      "position_ids tensor([[14]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 16])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 15 cache_length 15 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 16])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "position_ids tensor([[15]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 17])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 16 cache_length 16 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 17])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]])\n",
      "position_ids tensor([[16]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 18])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 17 cache_length 17 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 18])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]])\n",
      "position_ids tensor([[17]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 19])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 18 cache_length 18 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 19])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18]])\n",
      "position_ids tensor([[18]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 20])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 19 cache_length 19 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 20])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19]])\n",
      "position_ids tensor([[19]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 21])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 20 cache_length 20 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 21])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20]])\n",
      "position_ids tensor([[20]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 22])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 21 cache_length 21 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 22])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21]])\n",
      "position_ids tensor([[21]])\n",
      "in forward\n",
      "in prepare inputs for generation with args\n",
      "torch.Size([1, 23])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'NoneType'>\n",
      "<class 'torch.Tensor'>\n",
      "{'use_cache': True}\n",
      "past_length 22 cache_length 22 max_cache_length None\n",
      "input_ids case 2 before torch.Size([1, 23])\n",
      "input_ids case 2 after  torch.Size([1, 1])\n",
      "position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22]])\n",
      "position_ids tensor([[22]])\n",
      "in forward\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
